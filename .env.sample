# Your DataRobot API token.
# Refer to https://docs.datarobot.com/en/docs/api/api-quickstart/index.html#configure-your-environment for help.
DATAROBOT_API_TOKEN=

# The URL of your DataRobot instance API.
DATAROBOT_ENDPOINT=https://app.datarobot.com/api/v2

# The Pulumi stack name to use for this project.
PULUMI_STACK_NAME=dev

# If empty, a blank passphrase will be used
PULUMI_CONFIG_PASSPHRASE=123

# If empty, a new use case will be created
DATAROBOT_DEFAULT_USE_CASE=

# If empty, a new execution environment will be created for each agent using the docker_context folder
DATAROBOT_DEFAULT_EXECUTION_ENVIRONMENT="[DataRobot] Python 3.11 GenAI Agents"

# LLM Configuration:
# Agent templates support multiple flexible LLM options including:
# - LLM Gateway Direct (default)
# - LLM Blueprint with LLM Gateway
# - LLM Blueprint with an External LLM
# - Registered model such as an NVIDIA NIM
# - Already Deployed Text Generation model in DataRobot
#
# You can edit the LLM configuration by manually changing which configuration is
# active (recommended option).
# Simply run `ln -sf ../configurations/<chosen_configuration> llm.py`
# from the `infra/infra` folder
#
# If you want to do it dynamically however, you can also set it as a configuration value with:
# INFRA_ENABLE_LLM=<chosen_configuration>
# from the list of options in the infra/configurations/llm folder
# Here are some examples of each of those configuration using the dynamic option described above:

# If you want to use the LLM Gateway direct (default)
# INFRA_ENABLE_LLM=gateway_direct.py

# If you want to use an LLM Blueprint with the LLM Gateway to use VDBs and other features
# uncomment this:
# INFRA_ENABLE_LLM=blueprint_with_llm_gateway.py

# If you want to choose an existing LLM Deployment in DataRobot
# uncomment and configure these:
# TEXTGEN_DEPLOYMENT_ID=<your_deployment_id>
# INFRA_ENABLE_LLM=deployed_llm.py

# If you want to use a Registered Model with an LLM Blueprint
# like an NVIDIA NIM. This also shows how you can adjust the timeout
# in case getting a GPU takes a long time:
# DATAROBOT_TIMEOUT_MINUTES=120
# TEXTGEN_REGISTERED_MODEL_ID='<Your Registered Model ID>'
# INFRA_ENABLE_LLM=registered_model.py

# If you want to configure an LLM with an external LLM provider
# like Azure, Bedrock, Anthropic, or VertexAI (or all 4). Here we provide
# an Azure AI example, see:
# https://docs.datarobot.com/en/docs/gen-ai/playground-tools/deploy-llm.html
# for details on other providers and details:
# INFRA_ENABLE_LLM=blueprint_with_external_llm.py
# LLM_DEFAULT_MODEL="azure/gpt-4o"
# OPENAI_API_VERSION='2024-08-01-preview'
# OPENAI_API_BASE='https://<your_custom_endpoint>.openai.azure.com'
# OPENAI_API_DEPLOYMENT_ID='<your deployment_id>'
# OPENAI_API_KEY='<your_api_key>'

